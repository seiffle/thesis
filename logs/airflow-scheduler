
/home/airflow/.local/lib/python3.7/site-packages/airflow/www/utils.py:560 DeprecationWarning: 'jinja2.Markup' is deprecated and will be removed in Jinja 3.1. Import 'markupsafe.Markup' instead.
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2022-05-04 13:34:28,409] {scheduler_job.py:596} INFO - Starting the scheduler
[2022-05-04 13:34:28,409] {scheduler_job.py:601} INFO - Processing each file at most -1 times
[2022-05-04 13:34:28,673] {manager.py:163} INFO - Launched DagFileProcessorManager with pid: 36
[2022-05-04 13:34:28,675] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 13:34:28,684] {settings.py:52} INFO - Configured default timezone Timezone('UTC')
[2022-05-04 13:34:28,691] {settings.py:471} INFO - Loaded airflow_local_settings from /opt/airflow/config/airflow_local_settings.py .
[2022-05-04 13:39:28,749] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 13:44:28,797] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 13:49:28,843] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 13:54:28,899] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 13:59:28,948] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 14:04:28,997] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 14:09:29,054] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 14:14:29,104] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 14:18:32,940] {dag.py:2935} INFO - Setting next_dagrun for word-count to None
[2022-05-04 14:18:33,085] {scheduler_job.py:288} INFO - 1 tasks up for execution:
	<TaskInstance: word-count.split scheduled__2021-01-01T00:00:00+00:00 [scheduled]>
[2022-05-04 14:18:33,087] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2022-05-04 14:18:33,087] {scheduler_job.py:349} INFO - DAG word-count has 0/100 running and queued tasks
[2022-05-04 14:18:33,088] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.split scheduled__2021-01-01T00:00:00+00:00 [scheduled]>
[2022-05-04 14:18:33,090] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='split', run_id='scheduled__2021-01-01T00:00:00+00:00', try_number=1) to executor with priority 222 and queue default
[2022-05-04 14:18:33,090] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'split', 'scheduled__2021-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:18:33,274] {scheduler_job.py:510} INFO - Executor reports execution of word-count.split run_id=scheduled__2021-01-01T00:00:00+00:00 exited with status queued for try_number 1
[2022-05-04 14:18:33,283] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.split scheduled__2021-01-01T00:00:00+00:00 [queued]> to d6838073-0bda-4d3a-9269-963aac960ba2
[2022-05-04 14:18:34,673] {scheduler_job.py:510} INFO - Executor reports execution of word-count.split run_id=scheduled__2021-01-01T00:00:00+00:00 exited with status success for try_number 1
[2022-05-04 14:18:34,680] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=split, run_id=scheduled__2021-01-01T00:00:00+00:00, run_start_date=2022-05-04 14:18:33.706750+00:00, run_end_date=2022-05-04 14:18:33.923660+00:00, run_duration=0.21691, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=default, priority_weight=222, operator=KubernetesPodOperator
[2022-05-04 14:18:38,522] {dagrun.py:530} ERROR - Marking run <DagRun word-count @ 2021-01-01 00:00:00+00:00: scheduled__2021-01-01T00:00:00+00:00, externally triggered: False> failed
[2022-05-04 14:18:38,523] {dagrun.py:605} INFO - DagRun Finished: dag_id=word-count, execution_date=2021-01-01 00:00:00+00:00, run_id=scheduled__2021-01-01T00:00:00+00:00, run_start_date=2022-05-04 14:18:32.955411+00:00, run_end_date=2022-05-04 14:18:38.523049+00:00, run_duration=5.567638, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2021-01-01 00:00:00+00:00, data_interval_end=2021-01-01 00:00:00+00:00, dag_hash=6cb583845867a9c8993f0566b8035e73
[2022-05-04 14:18:38,526] {dag.py:2935} INFO - Setting next_dagrun for word-count to None
[2022-05-04 14:19:29,131] {scheduler_job.py:1114} INFO - Resetting orphaned tasks for active dag runs
[2022-05-04 14:21:55,853] {scheduler_job.py:288} INFO - 1 tasks up for execution:
	<TaskInstance: word-count.split manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:21:55,854] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2022-05-04 14:21:55,854] {scheduler_job.py:349} INFO - DAG word-count has 0/100 running and queued tasks
[2022-05-04 14:21:55,855] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.split manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:21:55,857] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='split', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 14 and queue default
[2022-05-04 14:21:55,857] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'split', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:21:55,898] {scheduler_job.py:510} INFO - Executor reports execution of word-count.split run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:21:55,904] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.split manual__2022-05-04T14:21:55.601050+00:00 [queued]> to da025bfb-4241-42ca-8cf6-7143a9a96c3a
[2022-05-04 14:22:04,232] {scheduler_job.py:288} INFO - 2 tasks up for execution:
	<TaskInstance: word-count.chunk-aa manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
	<TaskInstance: word-count.chunk-ab manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:04,234] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 2 task instances ready to be queued
[2022-05-04 14:22:04,234] {scheduler_job.py:349} INFO - DAG word-count has 0/100 running and queued tasks
[2022-05-04 14:22:04,234] {scheduler_job.py:349} INFO - DAG word-count has 1/100 running and queued tasks
[2022-05-04 14:22:04,235] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.chunk-aa manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
	<TaskInstance: word-count.chunk-ab manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:04,237] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='chunk-aa', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 7 and queue default
[2022-05-04 14:22:04,237] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'chunk-aa', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:04,237] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='chunk-ab', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 7 and queue default
[2022-05-04 14:22:04,237] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'chunk-ab', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:04,371] {scheduler_job.py:510} INFO - Executor reports execution of word-count.chunk-aa run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:04,371] {scheduler_job.py:510} INFO - Executor reports execution of word-count.chunk-ab run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:04,371] {scheduler_job.py:510} INFO - Executor reports execution of word-count.split run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:04,379] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.chunk-ab manual__2022-05-04T14:21:55.601050+00:00 [queued]> to 80f798a9-f72d-451c-b32a-bdf8dd71ea33
[2022-05-04 14:22:04,379] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.chunk-aa manual__2022-05-04T14:21:55.601050+00:00 [queued]> to 3acea885-5194-4dbf-8027-835bcac6a3a9
[2022-05-04 14:22:04,379] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=split, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:21:56.236442+00:00, run_end_date=2022-05-04 14:22:03.880284+00:00, run_duration=7.643842, state=success, executor_state=success, try_number=1, max_tries=0, job_id=5, pool=default_pool, queue=default, priority_weight=14, operator=KubernetesPodOperator
[2022-05-04 14:22:13,338] {scheduler_job.py:288} INFO - 2 tasks up for execution:
	<TaskInstance: word-count.word-count-aa-0 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
	<TaskInstance: word-count.word-count-aa-1 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:13,341] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 127 open slots and 2 task instances ready to be queued
[2022-05-04 14:22:13,341] {scheduler_job.py:349} INFO - DAG word-count has 1/100 running and queued tasks
[2022-05-04 14:22:13,341] {scheduler_job.py:349} INFO - DAG word-count has 2/100 running and queued tasks
[2022-05-04 14:22:13,342] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.word-count-aa-0 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
	<TaskInstance: word-count.word-count-aa-1 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:13,344] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='word-count-aa-0', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 4 and queue default
[2022-05-04 14:22:13,344] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'word-count-aa-0', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:13,344] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='word-count-aa-1', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 4 and queue default
[2022-05-04 14:22:13,344] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'word-count-aa-1', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:13,466] {scheduler_job.py:510} INFO - Executor reports execution of word-count.word-count-aa-0 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:13,467] {scheduler_job.py:510} INFO - Executor reports execution of word-count.word-count-aa-1 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:13,467] {scheduler_job.py:510} INFO - Executor reports execution of word-count.chunk-aa run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:13,475] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.word-count-aa-1 manual__2022-05-04T14:21:55.601050+00:00 [queued]> to c94ce97c-46a5-4191-843a-233c3a58a3de
[2022-05-04 14:22:13,475] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.word-count-aa-0 manual__2022-05-04T14:21:55.601050+00:00 [queued]> to 37a37c5e-d2e0-46bf-87d8-b82ed3f202dc
[2022-05-04 14:22:13,475] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=chunk-aa, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:04.582212+00:00, run_end_date=2022-05-04 14:22:13.130758+00:00, run_duration=8.548546, state=success, executor_state=success, try_number=1, max_tries=0, job_id=6, pool=default_pool, queue=default, priority_weight=7, operator=KubernetesPodOperator
[2022-05-04 14:22:14,623] {scheduler_job.py:288} INFO - 2 tasks up for execution:
	<TaskInstance: word-count.word-count-ab-0 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
	<TaskInstance: word-count.word-count-ab-1 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:14,625] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 126 open slots and 2 task instances ready to be queued
[2022-05-04 14:22:14,625] {scheduler_job.py:349} INFO - DAG word-count has 2/100 running and queued tasks
[2022-05-04 14:22:14,625] {scheduler_job.py:349} INFO - DAG word-count has 3/100 running and queued tasks
[2022-05-04 14:22:14,625] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.word-count-ab-0 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
	<TaskInstance: word-count.word-count-ab-1 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:14,627] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='word-count-ab-0', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 4 and queue default
[2022-05-04 14:22:14,628] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'word-count-ab-0', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:14,628] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='word-count-ab-1', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 4 and queue default
[2022-05-04 14:22:14,628] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'word-count-ab-1', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:14,829] {scheduler_job.py:510} INFO - Executor reports execution of word-count.word-count-ab-0 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:14,829] {scheduler_job.py:510} INFO - Executor reports execution of word-count.word-count-ab-1 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:14,829] {scheduler_job.py:510} INFO - Executor reports execution of word-count.chunk-ab run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:14,839] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.word-count-ab-1 manual__2022-05-04T14:21:55.601050+00:00 [queued]> to f488f25e-84a1-4afa-bc41-80034a511c73
[2022-05-04 14:22:14,839] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.word-count-ab-0 manual__2022-05-04T14:21:55.601050+00:00 [queued]> to c506d758-7c18-4d7b-aa64-081e41bb3d92
[2022-05-04 14:22:14,839] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=chunk-ab, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:04.638346+00:00, run_end_date=2022-05-04 14:22:14.262312+00:00, run_duration=9.623966, state=success, executor_state=success, try_number=1, max_tries=0, job_id=7, pool=default_pool, queue=default, priority_weight=7, operator=KubernetesPodOperator
[2022-05-04 14:22:19,533] {scheduler_job.py:288} INFO - 1 tasks up for execution:
	<TaskInstance: word-count.sort-aa-0 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:19,534] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 125 open slots and 1 task instances ready to be queued
[2022-05-04 14:22:19,535] {scheduler_job.py:349} INFO - DAG word-count has 3/100 running and queued tasks
[2022-05-04 14:22:19,535] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.sort-aa-0 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:19,537] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='sort-aa-0', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 3 and queue default
[2022-05-04 14:22:19,537] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'sort-aa-0', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:19,584] {scheduler_job.py:510} INFO - Executor reports execution of word-count.sort-aa-0 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:19,584] {scheduler_job.py:510} INFO - Executor reports execution of word-count.word-count-aa-0 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:19,591] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.sort-aa-0 manual__2022-05-04T14:21:55.601050+00:00 [queued]> to cf56d51c-838c-48e0-83d0-05431f3a54c8
[2022-05-04 14:22:19,591] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=word-count-aa-0, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:13.717999+00:00, run_end_date=2022-05-04 14:22:19.255022+00:00, run_duration=5.537023, state=success, executor_state=success, try_number=1, max_tries=0, job_id=9, pool=default_pool, queue=default, priority_weight=4, operator=KubernetesPodOperator
[2022-05-04 14:22:20,756] {scheduler_job.py:288} INFO - 1 tasks up for execution:
	<TaskInstance: word-count.sort-aa-1 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:20,758] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 125 open slots and 1 task instances ready to be queued
[2022-05-04 14:22:20,758] {scheduler_job.py:349} INFO - DAG word-count has 3/100 running and queued tasks
[2022-05-04 14:22:20,759] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.sort-aa-1 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:20,761] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='sort-aa-1', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 3 and queue default
[2022-05-04 14:22:20,761] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'sort-aa-1', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:20,839] {scheduler_job.py:510} INFO - Executor reports execution of word-count.sort-aa-1 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:20,839] {scheduler_job.py:510} INFO - Executor reports execution of word-count.word-count-aa-1 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:20,846] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.sort-aa-1 manual__2022-05-04T14:21:55.601050+00:00 [queued]> to 47268340-c176-43be-a756-058ff1525aa7
[2022-05-04 14:22:20,846] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=word-count-aa-1, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:13.666049+00:00, run_end_date=2022-05-04 14:22:20.300665+00:00, run_duration=6.634616, state=success, executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=default, priority_weight=4, operator=KubernetesPodOperator
[2022-05-04 14:22:22,473] {scheduler_job.py:288} INFO - 1 tasks up for execution:
	<TaskInstance: word-count.sort-ab-1 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:22,474] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 125 open slots and 1 task instances ready to be queued
[2022-05-04 14:22:22,475] {scheduler_job.py:349} INFO - DAG word-count has 3/100 running and queued tasks
[2022-05-04 14:22:22,475] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.sort-ab-1 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:22,477] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='sort-ab-1', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 3 and queue default
[2022-05-04 14:22:22,477] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'sort-ab-1', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:22,531] {scheduler_job.py:510} INFO - Executor reports execution of word-count.sort-ab-1 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:22,532] {scheduler_job.py:510} INFO - Executor reports execution of word-count.word-count-ab-1 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:22,539] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.sort-ab-1 manual__2022-05-04T14:21:55.601050+00:00 [queued]> to 71ef307e-e7b8-4317-9054-7e7ffd2a2763
[2022-05-04 14:22:22,540] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=word-count-ab-1, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:14.971191+00:00, run_end_date=2022-05-04 14:22:21.549450+00:00, run_duration=6.578259, state=success, executor_state=success, try_number=1, max_tries=0, job_id=10, pool=default_pool, queue=default, priority_weight=4, operator=KubernetesPodOperator
[2022-05-04 14:22:22,840] {scheduler_job.py:288} INFO - 1 tasks up for execution:
	<TaskInstance: word-count.sort-ab-0 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:22,842] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 125 open slots and 1 task instances ready to be queued
[2022-05-04 14:22:22,842] {scheduler_job.py:349} INFO - DAG word-count has 3/100 running and queued tasks
[2022-05-04 14:22:22,843] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.sort-ab-0 manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:22,845] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='sort-ab-0', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 3 and queue default
[2022-05-04 14:22:22,845] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'sort-ab-0', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:22,891] {scheduler_job.py:510} INFO - Executor reports execution of word-count.sort-ab-0 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:22,891] {scheduler_job.py:510} INFO - Executor reports execution of word-count.word-count-ab-0 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:22,899] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.sort-ab-0 manual__2022-05-04T14:21:55.601050+00:00 [queued]> to 331c6924-9ade-4142-9bf4-2356171b0129
[2022-05-04 14:22:22,899] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=word-count-ab-0, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:15.024145+00:00, run_end_date=2022-05-04 14:22:22.630346+00:00, run_duration=7.606201, state=success, executor_state=success, try_number=1, max_tries=0, job_id=11, pool=default_pool, queue=default, priority_weight=4, operator=KubernetesPodOperator
[2022-05-04 14:22:25,178] {scheduler_job.py:510} INFO - Executor reports execution of word-count.sort-aa-0 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:25,185] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=sort-aa-0, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:19.849880+00:00, run_end_date=2022-05-04 14:22:24.432241+00:00, run_duration=4.582361, state=success, executor_state=success, try_number=1, max_tries=0, job_id=12, pool=default_pool, queue=default, priority_weight=3, operator=KubernetesPodOperator
[2022-05-04 14:22:27,554] {scheduler_job.py:288} INFO - 1 tasks up for execution:
	<TaskInstance: word-count.merge-aa manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:27,561] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 127 open slots and 1 task instances ready to be queued
[2022-05-04 14:22:27,561] {scheduler_job.py:349} INFO - DAG word-count has 1/100 running and queued tasks
[2022-05-04 14:22:27,562] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.merge-aa manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:27,563] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='merge-aa', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 2 and queue default
[2022-05-04 14:22:27,564] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'merge-aa', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:27,612] {scheduler_job.py:510} INFO - Executor reports execution of word-count.merge-aa run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:27,612] {scheduler_job.py:510} INFO - Executor reports execution of word-count.sort-aa-1 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:27,613] {scheduler_job.py:510} INFO - Executor reports execution of word-count.sort-ab-1 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:27,622] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.merge-aa manual__2022-05-04T14:21:55.601050+00:00 [queued]> to eed0bea4-6b16-4260-81ee-21f606e87b61
[2022-05-04 14:22:27,622] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=sort-ab-1, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:22.804704+00:00, run_end_date=2022-05-04 14:22:27.344885+00:00, run_duration=4.540181, state=success, executor_state=success, try_number=1, max_tries=0, job_id=14, pool=default_pool, queue=default, priority_weight=3, operator=KubernetesPodOperator
[2022-05-04 14:22:27,622] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=sort-aa-1, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:21.019857+00:00, run_end_date=2022-05-04 14:22:26.578899+00:00, run_duration=5.559042, state=success, executor_state=success, try_number=1, max_tries=0, job_id=13, pool=default_pool, queue=default, priority_weight=3, operator=KubernetesPodOperator
[2022-05-04 14:22:28,790] {scheduler_job.py:288} INFO - 1 tasks up for execution:
	<TaskInstance: word-count.merge-ab manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:28,793] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 127 open slots and 1 task instances ready to be queued
[2022-05-04 14:22:28,793] {scheduler_job.py:349} INFO - DAG word-count has 1/100 running and queued tasks
[2022-05-04 14:22:28,794] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.merge-ab manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:28,796] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='merge-ab', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 2 and queue default
[2022-05-04 14:22:28,796] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'merge-ab', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:28,870] {scheduler_job.py:510} INFO - Executor reports execution of word-count.merge-ab run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:28,871] {scheduler_job.py:510} INFO - Executor reports execution of word-count.sort-ab-0 run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:28,877] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.merge-ab manual__2022-05-04T14:21:55.601050+00:00 [queued]> to 66b94348-df48-4cb4-bcf9-7415e155038e
[2022-05-04 14:22:28,878] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=sort-ab-0, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:23.137651+00:00, run_end_date=2022-05-04 14:22:28.704497+00:00, run_duration=5.566846, state=success, executor_state=success, try_number=1, max_tries=0, job_id=15, pool=default_pool, queue=default, priority_weight=3, operator=KubernetesPodOperator
[2022-05-04 14:22:33,728] {scheduler_job.py:288} INFO - 1 tasks up for execution:
	<TaskInstance: word-count.calc manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:33,730] {scheduler_job.py:322} INFO - Figuring out tasks to run in Pool(name=default_pool) with 128 open slots and 1 task instances ready to be queued
[2022-05-04 14:22:33,730] {scheduler_job.py:349} INFO - DAG word-count has 0/100 running and queued tasks
[2022-05-04 14:22:33,731] {scheduler_job.py:410} INFO - Setting the following tasks to queued state:
	<TaskInstance: word-count.calc manual__2022-05-04T14:21:55.601050+00:00 [scheduled]>
[2022-05-04 14:22:33,734] {scheduler_job.py:450} INFO - Sending TaskInstanceKey(dag_id='word-count', task_id='calc', run_id='manual__2022-05-04T14:21:55.601050+00:00', try_number=1) to executor with priority 1 and queue default
[2022-05-04 14:22:33,734] {base_executor.py:82} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'word-count', 'calc', 'manual__2022-05-04T14:21:55.601050+00:00', '--local', '--subdir', 'DAGS_FOLDER/main.py']
[2022-05-04 14:22:33,778] {scheduler_job.py:510} INFO - Executor reports execution of word-count.calc run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status queued for try_number 1
[2022-05-04 14:22:33,778] {scheduler_job.py:510} INFO - Executor reports execution of word-count.merge-aa run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:33,779] {scheduler_job.py:510} INFO - Executor reports execution of word-count.merge-ab run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:33,787] {scheduler_job.py:538} INFO - Setting external_id for <TaskInstance: word-count.calc manual__2022-05-04T14:21:55.601050+00:00 [queued]> to de383f86-9f56-4346-8b93-2ed0ef158737
[2022-05-04 14:22:33,787] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=merge-ab, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:29.049529+00:00, run_end_date=2022-05-04 14:22:33.591892+00:00, run_duration=4.542363, state=success, executor_state=success, try_number=1, max_tries=0, job_id=17, pool=default_pool, queue=default, priority_weight=2, operator=KubernetesPodOperator
[2022-05-04 14:22:33,787] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=merge-aa, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:27.868647+00:00, run_end_date=2022-05-04 14:22:32.519349+00:00, run_duration=4.650702, state=success, executor_state=success, try_number=1, max_tries=0, job_id=16, pool=default_pool, queue=default, priority_weight=2, operator=KubernetesPodOperator
[2022-05-04 14:22:39,023] {dagrun.py:545} INFO - Marking run <DagRun word-count @ 2022-05-04 14:21:55.601050+00:00: manual__2022-05-04T14:21:55.601050+00:00, externally triggered: True> successful
[2022-05-04 14:22:39,023] {dagrun.py:605} INFO - DagRun Finished: dag_id=word-count, execution_date=2022-05-04 14:21:55.601050+00:00, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:21:55.811257+00:00, run_end_date=2022-05-04 14:22:39.023515+00:00, run_duration=43.212258, state=success, external_trigger=True, run_type=manual, data_interval_start=2022-05-04 14:21:55.601050+00:00, data_interval_end=2022-05-04 14:21:55.601050+00:00, dag_hash=f0ebf3d422779e18af4aa75794565c03
[2022-05-04 14:22:39,025] {dag.py:2935} INFO - Setting next_dagrun for word-count to None
[2022-05-04 14:22:39,052] {scheduler_job.py:510} INFO - Executor reports execution of word-count.calc run_id=manual__2022-05-04T14:21:55.601050+00:00 exited with status success for try_number 1
[2022-05-04 14:22:39,057] {scheduler_job.py:563} INFO - TaskInstance Finished: dag_id=word-count, task_id=calc, run_id=manual__2022-05-04T14:21:55.601050+00:00, run_start_date=2022-05-04 14:22:34.055683+00:00, run_end_date=2022-05-04 14:22:38.603882+00:00, run_duration=4.548199, state=success, executor_state=success, try_number=1, max_tries=0, job_id=18, pool=default_pool, queue=default, priority_weight=1, operator=KubernetesPodOperator
